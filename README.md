# ğŸ§  AI Research Assistant

A fully containerized, production-ready AI Research Assistant that allows users to upload academic PDFs and ask natural language questions about their contents. Powered by open-source LLMs and a FAISS-based retrieval pipeline, the assistant delivers accurate, context-aware answers from research papers.

---

## ğŸš€ Features

- ğŸ” **PDF Ingestion & Chunking**: Automatically parses uploaded research papers into meaningful text chunks for efficient retrieval.
- ğŸ§  **Embedding & Vector Search**: Transforms text into vector representations using Hugging Face models and stores them in a **FAISS index** for fast semantic search.
- ğŸ—ƒï¸ **RAG-based QA System**: Combines dense retrieval with a decoder-only LLM (e.g., Falcon or Phi-2) for generating relevant, grounded answers.
- ğŸŒ **FastAPI Backend**: Clean, modular API built with FastAPI and served via **Docker**.
- ğŸ–¼ï¸ **Streamlit Frontend**: Lightweight, user-friendly interface for uploading files and interacting with the assistant.
- â˜ï¸ **Cloud Native**: Backend is fully containerized with Docker and deployed on cloud platforms like **AWS EC2** or **Hugging Face Spaces**.

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10**
- **FastAPI** â€“ for building RESTful APIs
- **Streamlit** â€“ for frontend UI
- **Hugging Face Transformers** â€“ for LLM and embeddings
- **FAISS** â€“ for fast vector similarity search
- **PyMuPDF / PDFMiner** â€“ for PDF parsing
- **Docker** â€“ for containerization and deployment
- **AWS EC2 / Hugging Face Spaces** â€“ for hosting backend

---

 ## TRY IT: https://ai-research-assist.streamlit.app/


